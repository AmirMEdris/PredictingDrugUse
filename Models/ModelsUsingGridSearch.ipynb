{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score,confusion_matrix,accuracy_score,classification_report\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,VotingClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures,StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df1 = pd.read_csv('../prepeddata.csv',index_col='Unnamed: 0')\n",
    "df1['stimulant'] = df1['stimulant'].apply(lambda x: 'low' if x <= 2 else 'high')\n",
    "\n",
    "RandomForestClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimx = df1.drop(['stimulant','hallucinagen','depressant'],axis = 1)\n",
    " \n",
    "stimy = df1.stimulant\n",
    "stimx\n",
    "\n",
    "sm = SMOTE()\n",
    "tl = TomekLinks()\n",
    "sampling = SMOTETomek(sampling_strategy='auto', random_state=None, smote=sm, tomek=tl, n_jobs=1)\n",
    "\n",
    "stimx, stimy = sampling.fit_resample(stimx, stimy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimXtrain,stimXtest,stimYtrain,stimYtest = train_test_split(stimx,stimy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268      low\n",
       "1766     low\n",
       "1887    high\n",
       "1186    high\n",
       "309      low\n",
       "        ... \n",
       "329      low\n",
       "263      low\n",
       "1852     low\n",
       "286      low\n",
       "3182    high\n",
       "Name: stimulant, Length: 2438, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stimscaler = StandardScaler()\n",
    "stimXtrain = stimscaler.fit_transform(stimXtrain)\n",
    "stimXtest = stimscaler.transform(stimXtest)\n",
    "stimYtrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sigma\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan 0.74816037 0.74816037\n",
      "        nan        nan        nan        nan 0.74569209 0.74569209\n",
      "        nan        nan        nan        nan 0.74610193 0.74610193\n",
      "        nan        nan        nan        nan 0.74610277 0.74610277]\n",
      "  category=UserWarning\n"
     ]
    }
   ],
   "source": [
    "logregparam_grid = {'C': [0.001,0.1,1, 10],'max_iter' :[1000],'class_weight':['auto'],'warm_start' :[True,False], 'solver': ['liblinear', 'rbf','sag']}\n",
    "mod = GridSearchCV(LogisticRegression(), logregparam_grid, n_jobs=-1, cv=5, verbose=1)\n",
    "mod.fit(stimXtrain,stimYtrain)\n",
    "stimtrianlogypred = mod.predict(stimXtrain)\n",
    "stimtestlogypred = mod.predict(stimXtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight='auto', max_iter=1000, solver='sag',\n",
       "                   warm_start=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardmodel1 = mod.best_estimator_\n",
    "standardmodel1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7495974723294041, 0.7673052205178671)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(stimYtrain,stimtrianlogypred,average='weighted'),f1_score(stimYtest,stimtestlogypred,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 720 candidates, totalling 2160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sigma\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.50574258 0.50574258 0.50574258 0.50163749 0.50163749\n",
      " 0.74364292 0.74364292 0.74364292 0.74364292 0.74364292        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.74364292 0.74364292 0.74446292\n",
      " 0.74897297 0.74487293        nan        nan        nan        nan\n",
      "        nan 0.74364292 0.74364292 0.74364292 0.74569395 0.73912984\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.750614   0.750614   0.750614   0.751024   0.75143451\n",
      " 0.74897499 0.74897499 0.74897499 0.74897499 0.7497955         nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.74897499 0.74897499 0.74897499\n",
      " 0.75020551 0.73748629        nan        nan        nan        nan\n",
      "        nan 0.74897499 0.74897499 0.74897499 0.75061501 0.748157\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.75020551 0.75020551 0.75020551 0.74774144 0.75061602\n",
      " 0.74938499 0.74938499 0.74938499 0.749795   0.750205          nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.74938499 0.74938499 0.74938499\n",
      " 0.7502045  0.73666477        nan        nan        nan        nan\n",
      "        nan 0.74938499 0.750205   0.75020551 0.75184653 0.74774195\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  category=UserWarning\n"
     ]
    }
   ],
   "source": [
    "logregparam_grid2 = {'tol': [0,0.0001,0.001,0.1,1]\n",
    "                     ,'C': [0,0.001,0.1,1]\n",
    "                     ,'penalty': ['l1','l2','elasticnet']\n",
    "                     ,'max_iter' :[1000],'class_weight':['auto']\n",
    "                     ,'warm_start' :[True]\n",
    "                     , 'solver': ['lbfgs','liblinear', 'rbf','sag','elasticnet','saga',]\n",
    "                     ,'dual':[False,True]\n",
    "                    }\n",
    "mod2 = GridSearchCV(LogisticRegression(), logregparam_grid2, n_jobs=-1, cv=3, verbose=1)\n",
    "mod2.fit(stimXtrain,stimYtrain)\n",
    "stimtrianlog2ypred = mod2.predict(stimXtrain)\n",
    "stimtestlog2ypred = mod2.predict(stimXtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight='auto', max_iter=1000, solver='saga',\n",
       "                   tol=0.1, warm_start=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardmodel2 = mod2.best_estimator_\n",
    "standardmodel2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8556228407643084, 0.8597782366188155)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(stimYtrain,stimtrianlog2ypred,average='weighted'),f1_score(stimYtest,stimtestlog2ypred,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sigma\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\Sigma\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_logistic.py:1319: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  \"(penalty={})\".format(self.penalty))\n"
     ]
    }
   ],
   "source": [
    "logregparam_grid3 = {'tol': [0,0.0001,0.001,0.1,1]\n",
    "                     ,'C': [0,0.001,0.1,1]\n",
    "                     ,'penalty': ['l1','l2','elasticnet']\n",
    "                     ,'max_iter' :[5000],'class_weight':['auto']\n",
    "                     \n",
    "                     , 'solver': ['lbfgs','liblinear', 'rbf','sag','elasticnet','saga',]\n",
    "                     ,'dual':[False,True],\"l1_ratio\":[None,0.01,0.1,0.2,0.3,0.4]\n",
    "                    ,'fit_intercept':[True,False]}\n",
    "mod3 = GridSearchCV(LogisticRegression(), logregparam_grid3, n_jobs=-1, cv=5, verbose=0)\n",
    "mod3.fit(stimXtrain,stimYtrain)\n",
    "stimtrianlog3ypred = mod3.predict(stimXtrain)\n",
    "stimtestlog3ypred = mod3.predict(stimXtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight='auto', fit_intercept=False, l1_ratio=0.2,\n",
       "                   max_iter=5000, penalty='l1', solver='saga', tol=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardmodel3 = mod3.best_estimator_\n",
    "standardmodel3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8536508699519856, 0.8657411971160501)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(stimYtrain,stimtrianlog3ypred,average='weighted'),f1_score(stimYtest,stimtestlog3ypred,average='weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n        high       0.82      0.91      0.86      1225\\n         low       0.90      0.80      0.85      1215\\n\\n    accuracy                           0.85      2440\\n   macro avg       0.86      0.85      0.85      2440\\nweighted avg       0.86      0.85      0.85      2440\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(stimYtrain,stimtrianlog3ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(standardmodel1,open('StandardModel1.pkl','wb'))\n",
    "pkl.dump(standardmodel2,open('StandardModel2.pkl','wb'))\n",
    "pkl.dump(standardmodel3,open('StandardModel3.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sigma\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py:72: FutureWarning: Pass criterion=DecisionTreeClassifier() as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12540 candidates, totalling 62700 fits\n"
     ]
    }
   ],
   "source": [
    "parameters={'min_samples_split' : range(10,500,45),'max_depth': range(1,20,1),'ccp_alpha':[x/300 for x in list(range(0,60,1))],'criterion':['gini']}\n",
    "dtc = GridSearchCV(DecisionTreeClassifier(DecisionTreeClassifier()),param_grid=parameters,verbose=True,n_jobs=-1)\n",
    "dtc.fit(stimXtrain,stimYtrain)\n",
    "dtcytrainpred = dtc.predict(stimXtrain)\n",
    "dtcytestpred = dtc.predict(stimXtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9044428483178419, 0.8660175551238114)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(stimYtrain,dtcytrainpred,average='weighted'),f1_score(stimYtest,dtcytestpred,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1320 candidates, totalling 6600 fits\n"
     ]
    }
   ],
   "source": [
    "parameters={'min_samples_split' : range(10,500,45),'ccp_alpha':[x/60 for x in list(range(0,60,1))],'criterion':['entropy','gini']}\n",
    "dtc2 = GridSearchCV(DecisionTreeClassifier(),param_grid=parameters,verbose=True,n_jobs=-1)\n",
    "dtc2.fit(stimXtrain,stimYtrain)\n",
    "dtcytrainpred = dtc2.predict(stimXtrain)\n",
    "dtcytestpred = dtc2.predict(stimXtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9118850830988885, 0.8685545347085643)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(stimYtrain,dtcytrainpred,average='weighted'),f1_score(stimYtest,dtcytestpred,average='weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3480 candidates, totalling 17400 fits\n"
     ]
    }
   ],
   "source": [
    "parameters={'min_impurity_decrease':[0+x/100 for x in range(1,30,1)],'ccp_alpha':[x/60 for x in list(range(0,60,1))],'criterion':['entropy','gini']}\n",
    "dtc3 = GridSearchCV(DecisionTreeClassifier(),param_grid=parameters,verbose=True,n_jobs=-1)\n",
    "dtc3.fit(stimXtrain,stimYtrain)\n",
    "dtcytrainpred = dtc3.predict(stimXtrain)\n",
    "dtcytestpred = dtc3.predict(stimXtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8897538946679115, 0.8611544185832243)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(stimYtrain,dtcytrainpred,average='weighted'),f1_score(stimYtest,dtcytestpred,average='weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardmodel4 = dtc.best_estimator_\n",
    "standardmodel5 = dtc2.best_estimator_\n",
    "standardmodel6 = dtc3.best_estimator_\n",
    "\n",
    "pkl.dump(standardmodel4,open('StandardModel4.pkl','wb'))\n",
    "pkl.dump(standardmodel5,open('StandardModel5.pkl','wb'))\n",
    "pkl.dump(standardmodel6,open('StandardModel6.pkl','wb'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knearest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 49 candidates, totalling 245 fits\n"
     ]
    }
   ],
   "source": [
    "# knn = KNeighborsClassifier(n_neighbors=43,weights='uniform')\n",
    "# knn.fit(stimXtrain,stimYtrain)\n",
    "# knntrainypred=knn.predict(stimXtrain)\n",
    "# knntestypred=knn.predict(stimXtest)\n",
    "# f1_score(stimYtrain,knntrainypred,average='weighted'),f1_score(stimYtest,knntestypred,average='weighted')\n",
    "parameters={'n_neighbors':range(1,50)}\n",
    "knn = GridSearchCV(KNeighborsClassifier(),param_grid=parameters,verbose=True,n_jobs=-1)\n",
    "knn.fit(stimXtrain,stimYtrain)\n",
    "knnytrainpred = knn.predict(stimXtrain)\n",
    "knnytestpred = knn.predict(stimXtest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1080 candidates, totalling 5400 fits\n"
     ]
    }
   ],
   "source": [
    "parameters={'n_neighbors':range(50,1130)}\n",
    "knn2 = GridSearchCV(KNeighborsClassifier(),param_grid=parameters,verbose=True,n_jobs=-1)\n",
    "knn2.fit(stimXtrain,stimYtrain)\n",
    "knn2ytrainpred = knn2.predict(stimXtrain)\n",
    "knn2ytestpred = knn2.predict(stimXtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardmodel7 = knn.best_estimator_\n",
    "standardmodel8 = knn2.best_estimator_\n",
    "\n",
    "pkl.dump(standardmodel7,open('StandardModel7.pkl','wb'))\n",
    "pkl.dump(standardmodel8,open('StandardModel8.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n"
     ]
    }
   ],
   "source": [
    "# rfc = RandomForestClassifier(criterion='gini',ccp_alpha=0.005,n_estimators=1000,max_features=6,class_weight='balanced',max_depth=6,oob_score=True)\n",
    "# rfc.fit(stimXtrain,stimYtrain)\n",
    "parameters={'ccp_alpha':[x/70 for x in list(range(0,30,1))],'class_weight':['balanced_subsample'],'criterion':['entropy'],'n_estimators':[100,300,500,750]}\n",
    "rfc = GridSearchCV(RandomForestClassifier(),param_grid=parameters,verbose=True,n_jobs=-1)\n",
    "rfc.fit(stimXtrain,stimYtrain)\n",
    "rfcytrainpred = rfc.predict(stimXtrain)\n",
    "rfcytestpred = rfc.predict(stimXtest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.9250952501227626)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfctrainypred = rfc.predict(stimXtrain)\n",
    "rfctestypred = rfc.predict(stimXtest)\n",
    "f1_score(rfctrainypred,stimYtrain,average='weighted'),f1_score(rfctestypred,stimYtest,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced_subsample', n_estimators=750)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters={'ccp_alpha':[x/70 for x in list(range(0,10,1))]\n",
    "                         ,'class_weight':['balanced_subsample'],'criterion':['gini']\n",
    "                         ,'n_estimators':[100,300,500,750]}\n",
    "rfc2 = GridSearchCV(RandomForestClassifier(),param_grid=parameters,verbose=True,n_jobs=-1)\n",
    "rfc2.fit(stimXtrain,stimYtrain)\n",
    "rfc2ytrainpred = rfc2.predict(stimXtrain)\n",
    "rfc2ytestpred = rfc2.predict(stimXtest)\n",
    "\n",
    "rfc2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.9226314098543239)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc2trainypred = rfc2.predict(stimXtrain)\n",
    "rfc2testypred = rfc2.predict(stimXtest)\n",
    "f1_score(rfc2trainypred,stimYtrain,average='weighted'),f1_score(rfc2testypred,stimYtest,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardmodel9 = rfc.best_estimator_\n",
    "standardmodel10 = rfc2.best_estimator_\n",
    "\n",
    "pkl.dump(standardmodel9,open('StandardModel9.pkl','wb'))\n",
    "pkl.dump(standardmodel10,open('StandardModel10.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('model1',\n",
       "                              LogisticRegression(C=10, class_weight='auto',\n",
       "                                                 max_iter=1000, solver='sag',\n",
       "                                                 warm_start=True)),\n",
       "                             ('model2',\n",
       "                              LogisticRegression(C=0.1, class_weight='auto',\n",
       "                                                 max_iter=1000, penalty='l1',\n",
       "                                                 solver='saga', tol=0,\n",
       "                                                 warm_start=True)),\n",
       "                             ('model3',\n",
       "                              LogisticRegression(C=1, class_weight='auto',\n",
       "                                                 fit_intercept=False,\n",
       "                                                 l1_ratio=0.2, max_iter=5000,\n",
       "                                                 pe...\n",
       "                              DecisionTreeClassifier(max_depth=5,\n",
       "                                                     min_samples_split=55)),\n",
       "                             ('model7', KNeighborsClassifier(n_neighbors=1)),\n",
       "                             ('model8', KNeighborsClassifier(n_neighbors=51)),\n",
       "                             ('model9',\n",
       "                              RandomForestClassifier(class_weight='balanced_subsample',\n",
       "                                                     criterion='entropy',\n",
       "                                                     n_estimators=500)),\n",
       "                             ('model10',\n",
       "                              RandomForestClassifier(class_weight='balanced_subsample',\n",
       "                                                     n_estimators=750))],\n",
       "                 n_jobs=-1, verbose=True, voting='soft')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vtc = VotingClassifier([('model1',standardmodel1),('model2',standardmodel2),('model3',standardmodel3)\n",
    "                        ,('model5',standardmodel5),('model6',standardmodel6),('model4',standardmodel4)\n",
    "                        ,('model7',standardmodel7),('model8',standardmodel8),('model9',standardmodel9)\n",
    "                        ,('model10',standardmodel10)],voting='soft',verbose = True,n_jobs=-1)\n",
    "vtc.fit(stimXtrain,stimYtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9488282087030745 0.8989299707303677\n"
     ]
    }
   ],
   "source": [
    "vtcypred = vtc.predict(stimXtest)\n",
    "vtcytrain = vtc.predict(stimXtrain)\n",
    "\n",
    "print(f1_score(vtcytrain,stimYtrain,average='weighted'),f1_score(stimYtest,vtcypred,average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(vtc,open('vtc.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.92      0.98      0.95      1225\n",
      "         low       0.98      0.92      0.95      1215\n",
      "\n",
      "    accuracy                           0.95      2440\n",
      "   macro avg       0.95      0.95      0.95      2440\n",
      "weighted avg       0.95      0.95      0.95      2440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(stimYtrain, vtcytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.85      0.96      0.90       402\n",
      "         low       0.96      0.84      0.89       412\n",
      "\n",
      "    accuracy                           0.90       814\n",
      "   macro avg       0.91      0.90      0.90       814\n",
      "weighted avg       0.91      0.90      0.90       814\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(stimYtest, vtcypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1201,   24],\n",
       "       [ 101, 1114]], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(stimYtrain, vtcytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[387,  15],\n",
       "       [ 67, 345]], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(stimYtest,vtcypred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
