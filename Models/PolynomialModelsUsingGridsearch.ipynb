{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score,confusion_matrix,accuracy_score,classification_report\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,VotingClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures,StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../polydf.csv',index_col='Unnamed: 0')\n",
    "df1 = pd.read_csv('../prepeddata.csv',index_col='Unnamed: 0')\n",
    "df1['stimulant'] = df1['stimulant'].apply(lambda x: 'low' if x <= 2 else 'high')\n",
    "df\n",
    "RandomForestClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimx = df1.drop(['stimulant','hallucinagen','depressant'],axis = 1)\n",
    "stimy = df1.stimulant\n",
    "stimx\n",
    "\n",
    "sm = SMOTE()\n",
    "tl = TomekLinks()\n",
    "sampling = SMOTETomek(sampling_strategy='auto', random_state=None, smote=sm, tomek=tl, n_jobs=1)\n",
    "\n",
    "stimx, stimy = sampling.fit_resample(stimx, stimy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimXtrain,stimXtest,stimYtrain,stimYtest = train_test_split(stimx,stimy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2930    high\n",
       "222      low\n",
       "3041    high\n",
       "3087    high\n",
       "2606    high\n",
       "        ... \n",
       "134      low\n",
       "228      low\n",
       "586      low\n",
       "2559    high\n",
       "171      low\n",
       "Name: stimulant, Length: 2437, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stimscaler = StandardScaler()\n",
    "stimXtrain = stimscaler.fit_transform(stimXtrain)\n",
    "stimXtest = stimscaler.transform(stimXtest)\n",
    "stimYtrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mod = LogisticRegression(class_weight = 'balanced'\n",
    "#                          ,max_iter=1000,solver='liblinear',warm_start=True,tol=0.2)\n",
    "# mod.fit(stimXtrain,stimYtrain)\n",
    "# stimtrianlogypred = mod.predict(stimXtrain)\n",
    "# stimtestlogypred = mod.predict(stimXtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 360 candidates, totalling 1800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sigma\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.7529833  0.7529833\n",
      "        nan        nan        nan        nan 0.75298246 0.75298246\n",
      "        nan        nan        nan        nan 0.75298415 0.75298415\n",
      "        nan        nan        nan        nan 0.75257431 0.75257431\n",
      "        nan        nan        nan        nan 0.75216363 0.75216363\n",
      "        nan        nan        nan        nan 0.75134396 0.75134396\n",
      "        nan        nan        nan        nan 0.75134564 0.75134564\n",
      "        nan        nan        nan        nan 0.75134564 0.75134564\n",
      "        nan        nan        nan        nan 0.75134564 0.75134564\n",
      "        nan        nan        nan        nan 0.75134564 0.75134564\n",
      "        nan        nan        nan        nan 0.75134564 0.75134564\n",
      "        nan        nan        nan        nan 0.75175548 0.75175548\n",
      "        nan        nan        nan        nan 0.75216616 0.75216616\n",
      "        nan        nan        nan        nan 0.75216616 0.75216616\n",
      "        nan        nan        nan        nan 0.75216616 0.75216616\n",
      "        nan        nan        nan        nan 0.75216616 0.75216616\n",
      "        nan        nan        nan        nan 0.75216616 0.75216616\n",
      "        nan        nan        nan        nan 0.75216616 0.75216616\n",
      "        nan        nan        nan        nan 0.75216616 0.75216616\n",
      "        nan        nan        nan        nan 0.75216616 0.75216616\n",
      "        nan        nan        nan        nan 0.75216616 0.75216616\n",
      "        nan        nan        nan        nan 0.75216616 0.75216616\n",
      "        nan        nan        nan        nan 0.75216616 0.75216616\n",
      "        nan        nan        nan        nan 0.75216616 0.75216616\n",
      "        nan        nan        nan        nan 0.75175632 0.75175632\n",
      "        nan        nan        nan        nan 0.75175632 0.75175632\n",
      "        nan        nan        nan        nan 0.75175632 0.75175632\n",
      "        nan        nan        nan        nan 0.75175632 0.75175632\n",
      "        nan        nan        nan        nan 0.75175632 0.75175632\n",
      "        nan        nan        nan        nan 0.75175632 0.75175632\n",
      "        nan        nan        nan        nan 0.75175632 0.75175632\n",
      "        nan        nan        nan        nan 0.75175632 0.75175632\n",
      "        nan        nan        nan        nan 0.75175632 0.75175632\n",
      "        nan        nan        nan        nan 0.75175632 0.75175632\n",
      "        nan        nan        nan        nan 0.75175632 0.75175632\n",
      "        nan        nan        nan        nan 0.75175632 0.75175632\n",
      "        nan        nan        nan        nan 0.75175632 0.75175632\n",
      "        nan        nan        nan        nan 0.75175632 0.75175632\n",
      "        nan        nan        nan        nan 0.75175632 0.75175632\n",
      "        nan        nan        nan        nan 0.75175632 0.75175632\n",
      "        nan        nan        nan        nan 0.75175632 0.75175632\n",
      "        nan        nan        nan        nan 0.75175632 0.75175632\n",
      "        nan        nan        nan        nan 0.75175632 0.75175632\n",
      "        nan        nan        nan        nan 0.75175632 0.75175632\n",
      "        nan        nan        nan        nan 0.75175632 0.75175632\n",
      "        nan        nan        nan        nan 0.75175632 0.75175632\n",
      "        nan        nan        nan        nan 0.75175632 0.75175632\n",
      "        nan        nan        nan        nan 0.75175632 0.75175632\n",
      "        nan        nan        nan        nan 0.75175632 0.75175632\n",
      "        nan        nan        nan        nan 0.75175632 0.75175632\n",
      "        nan        nan        nan        nan 0.75175632 0.75175632\n",
      "        nan        nan        nan        nan 0.75175632 0.75175632\n",
      "        nan        nan        nan        nan 0.75175632 0.75175632\n",
      "        nan        nan        nan        nan 0.75175632 0.75175632\n",
      "        nan        nan        nan        nan 0.75175632 0.75175632\n",
      "        nan        nan        nan        nan 0.75175632 0.75175632\n",
      "        nan        nan        nan        nan 0.75175632 0.75175632\n",
      "        nan        nan        nan        nan 0.75175632 0.75175632\n",
      "        nan        nan        nan        nan 0.75175632 0.75175632]\n",
      "  category=UserWarning\n"
     ]
    }
   ],
   "source": [
    "logregparam_grid = {'C':[x/60 for x in list(range(0,60,1))],'max_iter' :[1000],'class_weight':['auto'],'warm_start' :[True,False], 'solver': ['liblinear', 'rbf','sag']}\n",
    "mod = GridSearchCV(LogisticRegression(), logregparam_grid, n_jobs=-1, cv=5, verbose=1)\n",
    "mod.fit(stimXtrain,stimYtrain)\n",
    "stimtrianlogypred = mod.predict(stimXtrain)\n",
    "stimtestlogypred = mod.predict(stimXtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "polymodel1 = mod.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7487518011655647, 0.7396817200054929)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(stimYtrain,stimtrianlogypred,average='weighted'),f1_score(stimYtest,stimtestlogypred,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25920 candidates, totalling 129600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sigma\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  category=UserWarning\n"
     ]
    }
   ],
   "source": [
    "logregparam_grid2 = {'tol': [0,0.0001,0.001,0.1,1, 10]\n",
    "                     ,'C': [0,0.001,0.1,1, 10]\n",
    "                     ,'penalty': ['l1','l2','elasticnet']\n",
    "                     ,'max_iter' :[1000],'class_weight':['auto']\n",
    "                     ,'warm_start' :[True,False]\n",
    "                     , 'solver': ['lbfgs','liblinear', 'rbf','sag','elasticnet','saga',]\n",
    "                     ,'dual':[False,True],\"l1_ratio\":[None,0.01,0.1,0.2,0.3,0.4]\n",
    "                    ,'fit_intercept':[True,False]}\n",
    "mod2 = GridSearchCV(LogisticRegression(), logregparam_grid2, n_jobs=-1, cv=5, verbose=1)\n",
    "mod2.fit(stimXtrain,stimYtrain)\n",
    "stimtrianlog2ypred = mod2.predict(stimXtrain)\n",
    "stimtestlog2ypred = mod2.predict(stimXtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(stimYtrain,stimtrianlog2ypred,average='weighted'),f1_score(stimYtest,stimtestlog2ypred,average='weighted')\n",
    "polymodel2 = mod2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sigma\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.74455852 0.74455852 0.74373717 0.737577   0.73182752 0.7301848\n",
      " 0.74455852 0.74455852 0.74455852 0.74414784 0.74332649 0.74291581\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.74414784 0.74455852 0.74414784 0.73716632 0.71786448 0.71170431\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.74414784 0.74455852 0.74414784 0.73470226 0.72566735 0.72731006\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  category=UserWarning\n",
      "C:\\Users\\Sigma\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "logregparam_grid3 = {'tol': [0,0.0001,0.001,0.1,1, 10]\n",
    "                     ,'penalty': ['l1','l2','elasticnet']\n",
    "                     ,'max_iter' :[4000],'class_weight':['auto']\n",
    "                     ,'warm_start' :[True]\n",
    "                     , 'solver': ['lbfgs','liblinear', 'rbf','sag','elasticnet','saga']\n",
    "                    }\n",
    "mod3 = GridSearchCV(LogisticRegression(), logregparam_grid3, n_jobs=-1, cv=5, verbose=1)\n",
    "mod3.fit(stimXtrain,stimYtrain)\n",
    "stimtrianlog3ypred = mod3.predict(stimXtrain)\n",
    "stimtestlog3ypred = mod3.predict(stimXtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7513087818332471, 0.7398855443283363)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(stimYtrain,stimtrianlog3ypred,average='weighted'),f1_score(stimYtest,stimtestlog3ypred,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "polymodel3 = mod3.best_estimator_\n",
    "#('polymodel1',polymodel1),('polymodel1',polymodel2),('polymodel1',polymodel3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(polymodel1,open('PolyModel1.pkl','wb'))\n",
    "pkl.dump(polymodel2,open('PolyModel2.pkl','wb'))\n",
    "pkl.dump(polymodel3,open('PolyModel3.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 300 candidates, totalling 1500 fits\n"
     ]
    }
   ],
   "source": [
    "# dtc = DecisionTreeClassifier(criterion='gini',ccp_alpha=0.0055)\n",
    "# dtc.fit(stimXtrain,stimYtrain)\n",
    "# dtcytrainpred = dtc.predict(stimXtrain)\n",
    "# dtcytestpred = dtc.predict(stimXtest)\n",
    "parameters={'max_depth': range(1,20,1),'ccp_alpha':[x/60 for x in list(range(0,60,1))],'max_depth':[4,6,7,9,11],'criterion':['gini']}\n",
    "dtc = GridSearchCV(DecisionTreeClassifier(),param_grid=parameters,verbose=True,n_jobs=-1)\n",
    "dtc.fit(stimXtrain,stimYtrain)\n",
    "dtcytrainpred = dtc.predict(stimXtrain)\n",
    "dtcytestpred = dtc.predict(stimXtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9765843229111388, 0.843084895406015)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(stimYtrain,dtcytrainpred,average='weighted'),f1_score(stimYtest,dtcytestpred,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[370,  44],\n",
       "       [ 83, 315]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(stimYtest,dtcytestpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1200 candidates, totalling 6000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sigma\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.81848049 0.82874743 ... 0.50184805 0.50184805 0.50184805]\n",
      "  category=UserWarning\n"
     ]
    }
   ],
   "source": [
    "parameters={'criterion':['entropy','gini'],'min_samples_leaf':range(0,20,2),'ccp_alpha':[x/300 for x in list(range(0,60,1))]}\n",
    "dtc2 = GridSearchCV(DecisionTreeClassifier(),param_grid=parameters,verbose=True,n_jobs=-1)\n",
    "dtc2.fit(stimXtrain,stimYtrain)\n",
    "dtcytrainpred = dtc2.predict(stimXtrain)\n",
    "dtcytestpred = dtc2.predict(stimXtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9597505930743382, 0.8594967216147147)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(stimYtrain,dtcytrainpred,average='weighted'),f1_score(stimYtest,dtcytestpred,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[365,  49],\n",
       "       [ 65, 333]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(stimYtest,dtcytestpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18000 candidates, totalling 90000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sigma\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\model_selection\\_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan 0.7798768  0.7798768  ... 0.50184805 0.50184805 0.50184805]\n",
      "  category=UserWarning\n"
     ]
    }
   ],
   "source": [
    "# dtc3 = DecisionTreeClassifier(class_weight='balanced',criterion='gini',ccp_alpha=0.006599999)\n",
    "# dtc3.fit(stimXtrain,stimYtrain)\n",
    "# dtc3ytrainpred = dtc3.predict(stimXtrain)\n",
    "# dtc3ytestpred = dtc3.predict(stimXtest)\n",
    "parameters={'min_impurity_decrease':[0+x/100 for x in range(1,10)],'ccp_alpha':[x/60 for x in list(range(0,100,1))],'criterion':['entropy','gini'],'min_samples_leaf':range(0,20,2)}\n",
    "dtc3 = GridSearchCV(DecisionTreeClassifier(),param_grid=parameters,verbose=True,n_jobs=-1)\n",
    "dtc3.fit(stimXtrain,stimYtrain)\n",
    "dtcytrainpred = dtc3.predict(stimXtrain)\n",
    "dtcytestpred = dtc3.predict(stimXtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7943259846087922, 0.7745211469048117)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(stimYtrain,dtcytrainpred,average='weighted'),f1_score(stimYtest,dtcytestpred,average='weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "polymodel4 = dtc.best_estimator_\n",
    "polymodel5 = dtc2.best_estimator_\n",
    "polymodel6 = dtc3.best_estimator_\n",
    "\n",
    "pkl.dump(polymodel4,open('PolyModel4.pkl','wb'))\n",
    "pkl.dump(polymodel5,open('PolyModel5.pkl','wb'))\n",
    "pkl.dump(polymodel6,open('PolyModel6.pkl','wb'))\n",
    "#('polymodel1',polymodel1),('polymodel1',polymodel2),('polymodel1',polymodel3),('polymodel4',polymodel4),('polymodel5',polymodel5),('polymodel6',polymodel6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knearest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 49 candidates, totalling 245 fits\n"
     ]
    }
   ],
   "source": [
    "parameters={'n_neighbors':range(1,50)}\n",
    "knn = GridSearchCV(KNeighborsClassifier(),param_grid=parameters,verbose=True,n_jobs=-1)\n",
    "knn.fit(stimXtrain,stimYtrain)\n",
    "knnytrainpred = knn.predict(stimXtrain)\n",
    "knnytestpred = knn.predict(stimXtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1080 candidates, totalling 5400 fits\n"
     ]
    }
   ],
   "source": [
    "parameters={'n_neighbors':range(50,1130)}\n",
    "knn2 = GridSearchCV(KNeighborsClassifier(),param_grid=parameters,verbose=True,n_jobs=-1)\n",
    "knn2.fit(stimXtrain,stimYtrain)\n",
    "knn2ytrainpred = knn2.predict(stimXtrain)\n",
    "knn2ytestpred = knn2.predict(stimXtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "polymodel7 = knn.best_estimator_\n",
    "polymodel8 = knn2.best_estimator_\n",
    "\n",
    "#('polymodel1',polymodel1),('polymodel1',polymodel2),('polymodel1',polymodel3),('polymodel4',polymodel4),('polymodel5',polymodel5),('polymodel6',polymodel6),('polymodel7',polymodel7),('polymodel8',polymodel8)\n",
    "pkl.dump(polymodel7,open('PolyModel7.pkl','wb'))\n",
    "pkl.dump(polymodel8,open('PolyModel8.pkl','wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sigma\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\ensemble\\_forest.py:587: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn('class_weight presets \"balanced\" or '\n"
     ]
    }
   ],
   "source": [
    "parameters={'warm_start':[True,False],'class_weight':['balanced'],'criterion':['gini','entropy'],'n_estimators':[20,50,100,500]}\n",
    "rfc = GridSearchCV(RandomForestClassifier(),param_grid=parameters,verbose=True,n_jobs=-1)\n",
    "rfc.fit(stimXtrain,stimYtrain)\n",
    "rfcytrainpred = rfc.predict(stimXtrain)\n",
    "rfcytestpred = rfc.predict(stimXtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[393,  21],\n",
       "       [ 40, 358]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfctrainypred = rfc.predict(stimXtrain)\n",
    "rfctestypred = rfc.predict(stimXtest)\n",
    "f1_score(rfctrainypred,stimYtrain,average='weighted'),f1_score(rfctestypred,stimYtest,average='weighted')\n",
    "confusion_matrix(stimYtest,rfctestypred)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    }
   ],
   "source": [
    "parameters={'min_samples_leaf' : [3,5,7],'class_weight':['balanced'],'random_state':[True]\n",
    "                         ,'criterion':['gini']\n",
    "                         }\n",
    "rfc2 = GridSearchCV(RandomForestClassifier(),param_grid=parameters,verbose=True,n_jobs=-1)\n",
    "rfc2.fit(stimXtrain,stimYtrain)\n",
    "rfc2ytrainpred = rfc2.predict(stimXtrain)\n",
    "rfc2ytestpred = rfc2.predict(stimXtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9864476614609666, 0.9065793423798783)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc2trainypred = rfc2.predict(stimXtrain)\n",
    "rfc2testypred = rfc2.predict(stimXtest)\n",
    "f1_score(rfc2trainypred,stimYtrain,average='weighted'),f1_score(rfc2testypred,stimYtest,average='weighted')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "polymodel9 = rfc.best_estimator_\n",
    "polymodel10 = rfc2.best_estimator_\n",
    "#('polymodel1',polymodel1),('polymodel1',polymodel2),('polymodel1',polymodel3),('polymodel4',polymodel4),('polymodel5',polymodel5),('polymodel6',polymodel6),('polymodel7',polymodel7),('polymodel8',polymodel8),('polymodel9',polymodel9),('polymodel10',polymodel10)\n",
    "\n",
    "pkl.dump(polymodel9,open('PolyModel9.pkl','wb'))\n",
    "pkl.dump(polymodel10,open('PolyModel10.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('polymodel1',\n",
       "                              LogisticRegression(C=0.75, class_weight='auto',\n",
       "                                                 max_iter=1000, solver='sag',\n",
       "                                                 warm_start=True)),\n",
       "                             ('polymodel2',\n",
       "                              LogisticRegression(C=10, class_weight='auto',\n",
       "                                                 fit_intercept=False,\n",
       "                                                 max_iter=1000, tol=0,\n",
       "                                                 warm_start=True)),\n",
       "                             ('polymodel3',\n",
       "                              LogisticRegression(class_weight='auto',\n",
       "                                                 max_iter=4000, penalty='l1',\n",
       "                                                 solver='saga', tol=0,...\n",
       "                             ('polymodel7',\n",
       "                              KNeighborsClassifier(n_neighbors=1)),\n",
       "                             ('polymodel8',\n",
       "                              KNeighborsClassifier(n_neighbors=53)),\n",
       "                             ('polymodel9',\n",
       "                              RandomForestClassifier(class_weight='balanced',\n",
       "                                                     criterion='entropy',\n",
       "                                                     n_estimators=500,\n",
       "                                                     warm_start=True)),\n",
       "                             ('polymodel10',\n",
       "                              RandomForestClassifier(class_weight='balanced',\n",
       "                                                     min_samples_leaf=3,\n",
       "                                                     random_state=True))],\n",
       "                 n_jobs=-1, verbose=True, voting='soft')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "vtc = VotingClassifier([('polymodel1',polymodel1),('polymodel2',polymodel2),('polymodel3',polymodel3)\n",
    "                        ,('polymodel5',polymodel5),('polymodel6',polymodel6),('polymodel4',polymodel4)\n",
    "                        ,('polymodel7',polymodel7),('polymodel8',polymodel8),('polymodel9',polymodel9)\n",
    "                        ,('polymodel10',polymodel10)],voting='soft',verbose = True,n_jobs=-1)\n",
    "vtc.fit(stimXtrain,stimYtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9761856803751263 0.8747216414978388\n"
     ]
    }
   ],
   "source": [
    "vtcypred = vtc.predict(stimXtest)\n",
    "vtcytrain = vtc.predict(stimXtrain)\n",
    "\n",
    "print(f1_score(vtcytrain,stimYtrain,average='weighted'),f1_score(stimYtest,vtcypred,average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(vtc,open('vtcpoly.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1204,   49],\n",
       "       [   9, 1173]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(vtcytrain,stimYtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.96      0.99      0.98      1213\n",
      "         low       0.99      0.96      0.98      1222\n",
      "\n",
      "    accuracy                           0.98      2435\n",
      "   macro avg       0.98      0.98      0.98      2435\n",
      "weighted avg       0.98      0.98      0.98      2435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(stimYtrain, vtcytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.83      0.95      0.89       414\n",
      "         low       0.94      0.80      0.86       398\n",
      "\n",
      "    accuracy                           0.88       812\n",
      "   macro avg       0.89      0.87      0.87       812\n",
      "weighted avg       0.88      0.88      0.87       812\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(stimYtest, vtcypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
