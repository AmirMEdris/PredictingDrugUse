{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score,confusion_matrix,accuracy_score\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,VotingClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures,StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Escore</th>\n",
       "      <th>Ascore</th>\n",
       "      <th>Impulsive</th>\n",
       "      <th>Caff</th>\n",
       "      <th>Age Education</th>\n",
       "      <th>Age Escore</th>\n",
       "      <th>Age Oscore</th>\n",
       "      <th>Age Impulsive</th>\n",
       "      <th>Age SensationSeeking</th>\n",
       "      <th>Age Alchol</th>\n",
       "      <th>Age Caff</th>\n",
       "      <th>Age Nicotine</th>\n",
       "      <th>Education Impulsive</th>\n",
       "      <th>Education Alchol</th>\n",
       "      <th>Education Caff</th>\n",
       "      <th>Education Chocalate</th>\n",
       "      <th>Education Nicotine</th>\n",
       "      <th>Impulsive SensationSeeking</th>\n",
       "      <th>Impulsive Alchol</th>\n",
       "      <th>Impulsive Caff</th>\n",
       "      <th>Impulsive Chocalate</th>\n",
       "      <th>SensationSeeking Alchol</th>\n",
       "      <th>SensationSeeking Caff</th>\n",
       "      <th>SensationSeeking Chocalate</th>\n",
       "      <th>SensationSeeking Nicotine</th>\n",
       "      <th>Alchol Caff</th>\n",
       "      <th>Alchol Chocalate</th>\n",
       "      <th>Alchol Nicotine</th>\n",
       "      <th>Caff Chocalate</th>\n",
       "      <th>Caff Nicotine</th>\n",
       "      <th>Chocalate Nicotine</th>\n",
       "      <th>Age Education Impulsive</th>\n",
       "      <th>Age Education Chocalate</th>\n",
       "      <th>Education Caff Nicotine</th>\n",
       "      <th>Impulsive Alchol Caff</th>\n",
       "      <th>Impulsive Alchol Chocalate</th>\n",
       "      <th>Impulsive Caff Nicotine</th>\n",
       "      <th>Impulsive Chocalate Nicotine</th>\n",
       "      <th>SensationSeeking Alchol Chocalate</th>\n",
       "      <th>SensationSeeking Chocalate Nicotine</th>\n",
       "      <th>Alchol Chocalate Nicotine</th>\n",
       "      <th>Caff Chocalate Nicotine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <td>1.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>1.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>216.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884</th>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>216.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1885 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  Escore  Ascore  Impulsive  Caff  Age Education  Age Escore  \\\n",
       "0     3.0    36.0    37.0        4.0   6.0            3.0       108.0   \n",
       "1     2.0    52.0    48.0        3.0   6.0            8.0       104.0   \n",
       "2     3.0    45.0    32.0        2.0   6.0            3.0       135.0   \n",
       "3     1.0    34.0    47.0        2.0   5.0            3.0        34.0   \n",
       "4     3.0    28.0    41.0        4.0   6.0           12.0        84.0   \n",
       "...   ...     ...     ...        ...   ...            ...         ...   \n",
       "1880  1.0    51.0    48.0        7.0   4.0            0.0        51.0   \n",
       "1881  1.0    51.0    48.0        7.0   5.0            0.0        51.0   \n",
       "1882  2.0    30.0    31.0        6.0   6.0            4.0        60.0   \n",
       "1883  1.0    26.0    32.0        8.0   6.0            0.0        26.0   \n",
       "1884  1.0    53.0    50.0        7.0   6.0            0.0        53.0   \n",
       "\n",
       "      Age Oscore  Age Impulsive  Age SensationSeeking  Age Alchol  Age Caff  \\\n",
       "0          126.0           12.0                   9.0        15.0      18.0   \n",
       "1          110.0            6.0                  12.0        10.0      12.0   \n",
       "2          120.0            6.0                  24.0        18.0      18.0   \n",
       "3           46.0            2.0                   3.0         4.0       5.0   \n",
       "4          129.0           12.0                  18.0        12.0      18.0   \n",
       "...          ...            ...                   ...         ...       ...   \n",
       "1880        57.0            7.0                  11.0         5.0       4.0   \n",
       "1881        50.0            7.0                   9.0         5.0       5.0   \n",
       "1882        74.0           12.0                  10.0         8.0      12.0   \n",
       "1883        48.0            8.0                  10.0         5.0       6.0   \n",
       "1884        56.0            7.0                  10.0         4.0       6.0   \n",
       "\n",
       "      Age Nicotine  Education Impulsive  Education Alchol  Education Caff  \\\n",
       "0              6.0                  4.0               5.0             6.0   \n",
       "1              8.0                 12.0              20.0            24.0   \n",
       "2              0.0                  2.0               6.0             6.0   \n",
       "3              2.0                  6.0              12.0            15.0   \n",
       "4              6.0                 16.0              16.0            24.0   \n",
       "...            ...                  ...               ...             ...   \n",
       "1880           0.0                  0.0               0.0             0.0   \n",
       "1881           5.0                  0.0               0.0             0.0   \n",
       "1882          12.0                 12.0               8.0            12.0   \n",
       "1883           4.0                  0.0               0.0             0.0   \n",
       "1884           6.0                  0.0               0.0             0.0   \n",
       "\n",
       "      Education Chocalate  Education Nicotine  Impulsive SensationSeeking  \\\n",
       "0                     5.0                 2.0                        12.0   \n",
       "1                    24.0                16.0                        18.0   \n",
       "2                     4.0                 0.0                        16.0   \n",
       "3                    12.0                 6.0                         6.0   \n",
       "4                    24.0                 8.0                        24.0   \n",
       "...                   ...                 ...                         ...   \n",
       "1880                  0.0                 0.0                        77.0   \n",
       "1881                  0.0                 0.0                        63.0   \n",
       "1882                 12.0                12.0                        30.0   \n",
       "1883                  0.0                 0.0                        80.0   \n",
       "1884                  0.0                 0.0                        70.0   \n",
       "\n",
       "      Impulsive Alchol  Impulsive Caff  Impulsive Chocalate  \\\n",
       "0                 20.0            24.0                 20.0   \n",
       "1                 15.0            18.0                 18.0   \n",
       "2                 12.0            12.0                  8.0   \n",
       "3                  8.0            10.0                  8.0   \n",
       "4                 16.0            24.0                 24.0   \n",
       "...                ...             ...                  ...   \n",
       "1880              35.0            28.0                 28.0   \n",
       "1881              35.0            35.0                 28.0   \n",
       "1882              24.0            36.0                 36.0   \n",
       "1883              40.0            48.0                 40.0   \n",
       "1884              28.0            42.0                 42.0   \n",
       "\n",
       "      SensationSeeking Alchol  SensationSeeking Caff  \\\n",
       "0                        15.0                   18.0   \n",
       "1                        30.0                   36.0   \n",
       "2                        48.0                   48.0   \n",
       "3                        12.0                   15.0   \n",
       "4                        24.0                   36.0   \n",
       "...                       ...                    ...   \n",
       "1880                     55.0                   44.0   \n",
       "1881                     45.0                   45.0   \n",
       "1882                     20.0                   30.0   \n",
       "1883                     50.0                   60.0   \n",
       "1884                     40.0                   60.0   \n",
       "\n",
       "      SensationSeeking Chocalate  SensationSeeking Nicotine  Alchol Caff  \\\n",
       "0                           15.0                        6.0         30.0   \n",
       "1                           36.0                       24.0         30.0   \n",
       "2                           32.0                        0.0         36.0   \n",
       "3                           12.0                        6.0         20.0   \n",
       "4                           36.0                       12.0         24.0   \n",
       "...                          ...                        ...          ...   \n",
       "1880                        44.0                        0.0         20.0   \n",
       "1881                        36.0                       45.0         25.0   \n",
       "1882                        30.0                       30.0         24.0   \n",
       "1883                        50.0                       40.0         30.0   \n",
       "1884                        60.0                       60.0         24.0   \n",
       "\n",
       "      Alchol Chocalate  Alchol Nicotine  Caff Chocalate  Caff Nicotine  \\\n",
       "0                 25.0             10.0            30.0           12.0   \n",
       "1                 30.0             20.0            36.0           24.0   \n",
       "2                 24.0              0.0            24.0            0.0   \n",
       "3                 16.0              8.0            20.0           10.0   \n",
       "4                 24.0              8.0            36.0           12.0   \n",
       "...                ...              ...             ...            ...   \n",
       "1880              20.0              0.0            16.0            0.0   \n",
       "1881              20.0             25.0            20.0           25.0   \n",
       "1882              24.0             24.0            36.0           36.0   \n",
       "1883              25.0             20.0            30.0           24.0   \n",
       "1884              24.0             24.0            36.0           36.0   \n",
       "\n",
       "      Chocalate Nicotine  Age Education Impulsive  Age Education Chocalate  \\\n",
       "0                   10.0                     12.0                     15.0   \n",
       "1                   24.0                     24.0                     48.0   \n",
       "2                    0.0                      6.0                     12.0   \n",
       "3                    8.0                      6.0                     12.0   \n",
       "4                   12.0                     48.0                     72.0   \n",
       "...                  ...                      ...                      ...   \n",
       "1880                 0.0                      0.0                      0.0   \n",
       "1881                20.0                      0.0                      0.0   \n",
       "1882                36.0                     24.0                     24.0   \n",
       "1883                20.0                      0.0                      0.0   \n",
       "1884                36.0                      0.0                      0.0   \n",
       "\n",
       "      Education Caff Nicotine  Impulsive Alchol Caff  \\\n",
       "0                        12.0                  120.0   \n",
       "1                        96.0                   90.0   \n",
       "2                         0.0                   72.0   \n",
       "3                        30.0                   40.0   \n",
       "4                        48.0                   96.0   \n",
       "...                       ...                    ...   \n",
       "1880                      0.0                  140.0   \n",
       "1881                      0.0                  175.0   \n",
       "1882                     72.0                  144.0   \n",
       "1883                      0.0                  240.0   \n",
       "1884                      0.0                  168.0   \n",
       "\n",
       "      Impulsive Alchol Chocalate  Impulsive Caff Nicotine  \\\n",
       "0                          100.0                     48.0   \n",
       "1                           90.0                     72.0   \n",
       "2                           48.0                      0.0   \n",
       "3                           32.0                     20.0   \n",
       "4                           96.0                     48.0   \n",
       "...                          ...                      ...   \n",
       "1880                       140.0                      0.0   \n",
       "1881                       140.0                    175.0   \n",
       "1882                       144.0                    216.0   \n",
       "1883                       200.0                    192.0   \n",
       "1884                       168.0                    252.0   \n",
       "\n",
       "      Impulsive Chocalate Nicotine  SensationSeeking Alchol Chocalate  \\\n",
       "0                             40.0                               75.0   \n",
       "1                             72.0                              180.0   \n",
       "2                              0.0                              192.0   \n",
       "3                             16.0                               48.0   \n",
       "4                             48.0                              144.0   \n",
       "...                            ...                                ...   \n",
       "1880                           0.0                              220.0   \n",
       "1881                         140.0                              180.0   \n",
       "1882                         216.0                              120.0   \n",
       "1883                         160.0                              250.0   \n",
       "1884                         252.0                              240.0   \n",
       "\n",
       "      SensationSeeking Chocalate Nicotine  Alchol Chocalate Nicotine  \\\n",
       "0                                    30.0                       50.0   \n",
       "1                                   144.0                      120.0   \n",
       "2                                     0.0                        0.0   \n",
       "3                                    24.0                       32.0   \n",
       "4                                    72.0                       48.0   \n",
       "...                                   ...                        ...   \n",
       "1880                                  0.0                        0.0   \n",
       "1881                                180.0                      100.0   \n",
       "1882                                180.0                      144.0   \n",
       "1883                                200.0                      100.0   \n",
       "1884                                360.0                      144.0   \n",
       "\n",
       "      Caff Chocalate Nicotine  \n",
       "0                        60.0  \n",
       "1                       144.0  \n",
       "2                         0.0  \n",
       "3                        40.0  \n",
       "4                        72.0  \n",
       "...                       ...  \n",
       "1880                      0.0  \n",
       "1881                    100.0  \n",
       "1882                    216.0  \n",
       "1883                    120.0  \n",
       "1884                    216.0  \n",
       "\n",
       "[1885 rows x 43 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('polydf.csv',index_col='Unnamed: 0')\n",
    "df1 = pd.read_csv('prepeddata.csv',index_col='Unnamed: 0')\n",
    "df1['stimulant'] = df1['stimulant'].apply(lambda x: 'None' if x == 0 else 'low' if x <= 2 else 'high')\n",
    "df\n",
    "RandomForestClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1        low\n",
       "2        low\n",
       "3       None\n",
       "4        low\n",
       "5        low\n",
       "        ... \n",
       "1884    None\n",
       "1885    None\n",
       "1886    high\n",
       "1887    None\n",
       "1888     low\n",
       "Name: stimulant, Length: 1885, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stimtestdata = df1.drop(['hallucinagen','depressant'],axis = 1)\n",
    "stimx = df\n",
    "stimy = stimtestdata.stimulant\n",
    "stimy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimXtrain,stimXtest,stimYtrain,stimYtest = train_test_split(stimx,stimy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "767     high\n",
       "1113    None\n",
       "422      low\n",
       "1248    None\n",
       "1159    high\n",
       "        ... \n",
       "1846     low\n",
       "1478     low\n",
       "1707    None\n",
       "232     None\n",
       "96       low\n",
       "Name: stimulant, Length: 1413, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stimscaler = StandardScaler()\n",
    "stimXtrain = stimscaler.fit_transform(stimXtrain)\n",
    "stimXtest = stimscaler.transform(stimXtest)\n",
    "stimYtrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mod = LogisticRegression(class_weight = 'balanced'\n",
    "#                          ,max_iter=1000,solver='liblinear',warm_start=True,tol=0.2)\n",
    "# mod.fit(stimXtrain,stimYtrain)\n",
    "# stimtrianlogypred = mod.predict(stimXtrain)\n",
    "# stimtestlogypred = mod.predict(stimXtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:    3.6s finished\n"
     ]
    }
   ],
   "source": [
    "logregparam_grid = {'C': [0.001,0.1,1, 10],'max_iter' :[1000],'class_weight':['balanced'],'warm_start' :[True,False], 'solver': ['liblinear', 'rbf','sag']}\n",
    "mod = GridSearchCV(LogisticRegression(), logregparam_grid, n_jobs=-1, cv=5, verbose=1)\n",
    "mod.fit(stimXtrain,stimYtrain)\n",
    "stimtrianlogypred = mod.predict(stimXtrain)\n",
    "stimtestlogypred = mod.predict(stimXtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "polymodel1 = mod.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6139750898125526, 0.6120656466101112)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(stimYtrain,stimtrianlogypred,average='weighted'),f1_score(stimYtest,stimtestlogypred,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 51840 candidates, totalling 259200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1048 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 16536 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done 38936 tasks      | elapsed:   15.3s\n",
      "[Parallel(n_jobs=-1)]: Done 57666 tasks      | elapsed:   36.2s\n",
      "[Parallel(n_jobs=-1)]: Done 64492 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 86448 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 106104 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 110566 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 117164 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 138841 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 158332 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done 165877 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 187177 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=-1)]: Done 196300 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=-1)]: Done 214232 tasks      | elapsed: 11.4min\n",
      "[Parallel(n_jobs=-1)]: Done 228880 tasks      | elapsed: 13.3min\n",
      "[Parallel(n_jobs=-1)]: Done 240381 tasks      | elapsed: 15.6min\n",
      "[Parallel(n_jobs=-1)]: Done 256704 tasks      | elapsed: 17.4min\n",
      "[Parallel(n_jobs=-1)]: Done 259200 out of 259200 | elapsed: 17.8min finished\n"
     ]
    }
   ],
   "source": [
    "logregparam_grid2 = {'tol': [0,0.0001,0.001,0.1,1, 10]\n",
    "                     ,'C': [0,0.001,0.1,1, 10]\n",
    "                     ,'penalty': ['l1','l2','elasticnet']\n",
    "                     ,'max_iter' :[1000],'class_weight':[None,'balanced']\n",
    "                     ,'warm_start' :[True,False]\n",
    "                     , 'solver': ['lbfgs','liblinear', 'rbf','sag','elasticnet','saga',]\n",
    "                     ,'dual':[False,True],\"l1_ratio\":[None,0.01,0.1,0.2,0.3,0.4]\n",
    "                    ,'fit_intercept':[True,False]}\n",
    "mod2 = GridSearchCV(LogisticRegression(), logregparam_grid2, n_jobs=-1, cv=5, verbose=1)\n",
    "mod2.fit(stimXtrain,stimYtrain)\n",
    "stimtrianlog2ypred = mod2.predict(stimXtrain)\n",
    "stimtestlog2ypred = mod2.predict(stimXtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "polymodel2 = mod2.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6147996041951862, 0.6337016801279772)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(stimYtrain,stimtrianlog2ypred,average='weighted'),f1_score(stimYtest,stimtestlog2ypred,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod3 = LogisticRegression(class_weight='balanced',max_iter=4000,solver='liblinear',tol=1)\n",
    "mod3.fit(stimXtrain,stimYtrain)\n",
    "stimtrianlog3ypred = mod3.predict(stimXtrain)\n",
    "stimtestlog3ypred = mod3.predict(stimXtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1315: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\"l1_ratio parameter is only used when penalty is \"\n"
     ]
    }
   ],
   "source": [
    "logregparam_grid3 = {'tol': [0,0.0001,0.001,0.1,1, 10]\n",
    "                     ,'C': [0,0.001,0.1,1, 10]\n",
    "                     ,'penalty': ['l1','l2','elasticnet']\n",
    "                     ,'max_iter' :[1000],'class_weight':[None]\n",
    "                     ,'warm_start' :[True,False]\n",
    "                     , 'solver': ['lbfgs','liblinear', 'rbf','sag','elasticnet','saga',]\n",
    "                     ,'dual':[False,True],\"l1_ratio\":[None,0.01,0.1,0.2,0.3,0.4]\n",
    "                    ,'fit_intercept':[True,False]}\n",
    "mod3 = GridSearchCV(LogisticRegression(), logregparam_grid3, n_jobs=-1, cv=5, verbose=0)\n",
    "mod3.fit(stimXtrain,stimYtrain)\n",
    "stimtrianlog3ypred = mod3.predict(stimXtrain)\n",
    "stimtestlog3ypred = mod3.predict(stimXtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.620902801614365, 0.6494737983830857)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(stimYtrain,stimtrianlog3ypred,average='weighted'),f1_score(stimYtest,stimtestlog3ypred,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "polymodel3 =mod3.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(polymodel1,open('PolyModel1.pkl','wb'))\n",
    "pkl.dump(polymodel2,open('PolyModel2.pkl','wb'))\n",
    "pkl.dump(polymodel3,open('PolyModel3.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 33060 candidates, totalling 165300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2536 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 10536 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done 21736 tasks      | elapsed:   20.1s\n",
      "[Parallel(n_jobs=-1)]: Done 36136 tasks      | elapsed:   34.2s\n",
      "[Parallel(n_jobs=-1)]: Done 53736 tasks      | elapsed:   50.5s\n",
      "[Parallel(n_jobs=-1)]: Done 74536 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 98536 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 125736 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 156136 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 165300 out of 165300 | elapsed:  2.6min finished\n"
     ]
    }
   ],
   "source": [
    "# dtc = DecisionTreeClassifier(criterion='gini',ccp_alpha=0.0055)\n",
    "# dtc.fit(stimXtrain,stimYtrain)\n",
    "# dtcytrainpred = dtc.predict(stimXtrain)\n",
    "# dtcytestpred = dtc.predict(stimXtest)\n",
    "parameters={'max_depth': range(1,20,1),'ccp_alpha':[x/60 for x in list(range(0,60,1))],'max_features':range(1,30,1),'class_weight':['balanced'],'criterion':['gini']}\n",
    "dtc = GridSearchCV(DecisionTreeClassifier(),param_grid=parameters,verbose=True,n_jobs=-1)\n",
    "dtc.fit(stimXtrain,stimYtrain)\n",
    "dtcytrainpred = dtc.predict(stimXtrain)\n",
    "dtcytestpred = dtc.predict(stimXtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5095389453459878, 0.4810187857320941)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(stimYtrain,dtcytrainpred,average='weighted'),f1_score(stimYtest,dtcytestpred,average='weighted')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1653000 candidates, totalling 8265000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1048 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 9048 tasks      | elapsed:   16.7s\n",
      "[Parallel(n_jobs=-1)]: Done 20248 tasks      | elapsed:   34.6s\n",
      "[Parallel(n_jobs=-1)]: Done 34648 tasks      | elapsed:   59.0s\n",
      "[Parallel(n_jobs=-1)]: Done 52248 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 66528 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 84528 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 104928 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 127728 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 152928 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 180528 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 210528 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 242928 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 277728 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=-1)]: Done 314928 tasks      | elapsed:  8.6min\n",
      "[Parallel(n_jobs=-1)]: Done 354528 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=-1)]: Done 396528 tasks      | elapsed: 10.8min\n",
      "[Parallel(n_jobs=-1)]: Done 440928 tasks      | elapsed: 12.0min\n",
      "[Parallel(n_jobs=-1)]: Done 487728 tasks      | elapsed: 13.3min\n",
      "[Parallel(n_jobs=-1)]: Done 536928 tasks      | elapsed: 14.6min\n",
      "[Parallel(n_jobs=-1)]: Done 588528 tasks      | elapsed: 16.0min\n",
      "[Parallel(n_jobs=-1)]: Done 642528 tasks      | elapsed: 17.4min\n",
      "[Parallel(n_jobs=-1)]: Done 698928 tasks      | elapsed: 18.9min\n",
      "[Parallel(n_jobs=-1)]: Done 745120 tasks      | elapsed: 20.3min\n",
      "[Parallel(n_jobs=-1)]: Done 826720 tasks      | elapsed: 22.5min\n",
      "[Parallel(n_jobs=-1)]: Done 885480 tasks      | elapsed: 24.1min\n",
      "[Parallel(n_jobs=-1)]: Done 918480 tasks      | elapsed: 25.0min\n",
      "[Parallel(n_jobs=-1)]: Done 952680 tasks      | elapsed: 25.9min\n",
      "[Parallel(n_jobs=-1)]: Done 988080 tasks      | elapsed: 26.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1024680 tasks      | elapsed: 27.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1062480 tasks      | elapsed: 28.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1101480 tasks      | elapsed: 30.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1141680 tasks      | elapsed: 31.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1183080 tasks      | elapsed: 32.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1225680 tasks      | elapsed: 33.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1270880 tasks      | elapsed: 34.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1330880 tasks      | elapsed: 36.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1392480 tasks      | elapsed: 38.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1455680 tasks      | elapsed: 40.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1517600 tasks      | elapsed: 42.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1584000 tasks      | elapsed: 44.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1652000 tasks      | elapsed: 45.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1721600 tasks      | elapsed: 48.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1791984 tasks      | elapsed: 50.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1864784 tasks      | elapsed: 52.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1939184 tasks      | elapsed: 54.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2014032 tasks      | elapsed: 56.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2091632 tasks      | elapsed: 58.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2170832 tasks      | elapsed: 59.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2251632 tasks      | elapsed: 61.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2334032 tasks      | elapsed: 63.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2418032 tasks      | elapsed: 65.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2503632 tasks      | elapsed: 67.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2590832 tasks      | elapsed: 69.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2679632 tasks      | elapsed: 70.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2770032 tasks      | elapsed: 72.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2862032 tasks      | elapsed: 74.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2955632 tasks      | elapsed: 76.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3050832 tasks      | elapsed: 78.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3227728 tasks      | elapsed: 82.6min\n",
      "[Parallel(n_jobs=-1)]: Done 3408400 tasks      | elapsed: 86.9min\n",
      "[Parallel(n_jobs=-1)]: Done 3469008 tasks      | elapsed: 88.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3570608 tasks      | elapsed: 91.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3673808 tasks      | elapsed: 93.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3778608 tasks      | elapsed: 96.4min\n",
      "[Parallel(n_jobs=-1)]: Done 3879376 tasks      | elapsed: 98.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3962240 tasks      | elapsed: 101.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4071840 tasks      | elapsed: 103.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4183040 tasks      | elapsed: 106.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4349632 tasks      | elapsed: 110.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4454700 tasks      | elapsed: 113.5min\n",
      "[Parallel(n_jobs=-1)]: Done 4515100 tasks      | elapsed: 115.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4573900 tasks      | elapsed: 117.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4633500 tasks      | elapsed: 119.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4812948 tasks      | elapsed: 124.2min\n",
      "[Parallel(n_jobs=-1)]: Done 4970556 tasks      | elapsed: 128.4min\n",
      "[Parallel(n_jobs=-1)]: Done 5097204 tasks      | elapsed: 132.0min\n",
      "[Parallel(n_jobs=-1)]: Done 5222804 tasks      | elapsed: 135.5min\n",
      "[Parallel(n_jobs=-1)]: Done 5350004 tasks      | elapsed: 139.0min\n",
      "[Parallel(n_jobs=-1)]: Done 5478804 tasks      | elapsed: 142.7min\n",
      "[Parallel(n_jobs=-1)]: Done 5609204 tasks      | elapsed: 146.4min\n",
      "[Parallel(n_jobs=-1)]: Done 5690308 tasks      | elapsed: 148.8min\n",
      "[Parallel(n_jobs=-1)]: Done 5792628 tasks      | elapsed: 151.9min\n",
      "[Parallel(n_jobs=-1)]: Done 5927828 tasks      | elapsed: 155.7min\n",
      "[Parallel(n_jobs=-1)]: Done 6064628 tasks      | elapsed: 159.6min\n",
      "[Parallel(n_jobs=-1)]: Done 6203028 tasks      | elapsed: 163.6min\n",
      "[Parallel(n_jobs=-1)]: Done 6343028 tasks      | elapsed: 167.5min\n",
      "[Parallel(n_jobs=-1)]: Done 6483812 tasks      | elapsed: 171.7min\n",
      "[Parallel(n_jobs=-1)]: Done 6627012 tasks      | elapsed: 175.8min\n",
      "[Parallel(n_jobs=-1)]: Done 6771812 tasks      | elapsed: 179.9min\n",
      "[Parallel(n_jobs=-1)]: Done 6918212 tasks      | elapsed: 184.1min\n",
      "[Parallel(n_jobs=-1)]: Done 7066212 tasks      | elapsed: 188.3min\n",
      "[Parallel(n_jobs=-1)]: Done 7215812 tasks      | elapsed: 192.6min\n",
      "[Parallel(n_jobs=-1)]: Done 7292860 tasks      | elapsed: 194.9min\n",
      "[Parallel(n_jobs=-1)]: Done 7369260 tasks      | elapsed: 197.2min\n",
      "[Parallel(n_jobs=-1)]: Done 7518860 tasks      | elapsed: 201.4min\n",
      "[Parallel(n_jobs=-1)]: Done 7674860 tasks      | elapsed: 205.7min\n",
      "[Parallel(n_jobs=-1)]: Done 7832460 tasks      | elapsed: 210.1min\n",
      "[Parallel(n_jobs=-1)]: Done 7991660 tasks      | elapsed: 214.5min\n",
      "[Parallel(n_jobs=-1)]: Done 8152460 tasks      | elapsed: 218.5min\n",
      "[Parallel(n_jobs=-1)]: Done 8265000 out of 8265000 | elapsed: 220.2min finished\n"
     ]
    }
   ],
   "source": [
    "parameters={'min_samples_split' : range(10,500,20),'max_depth': range(1,20,1),'ccp_alpha':[x/60 for x in list(range(0,60,1))],'max_features':range(1,30,1),'class_weight':['balanced'],'criterion':['entropy','gini']}\n",
    "dtc2 = GridSearchCV(DecisionTreeClassifier(),param_grid=parameters,verbose=True,n_jobs=-1)\n",
    "dtc2.fit(stimXtrain,stimYtrain)\n",
    "dtcytrainpred = dtc2.predict(stimXtrain)\n",
    "dtcytestpred = dtc2.predict(stimXtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5279100310593331, 0.46591941360057926)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(stimYtrain,dtcytrainpred,average='weighted'),f1_score(stimYtest,dtcytestpred,average='weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18000 candidates, totalling 90000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1048 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 9048 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done 20248 tasks      | elapsed:   18.6s\n",
      "[Parallel(n_jobs=-1)]: Done 34648 tasks      | elapsed:   30.8s\n",
      "[Parallel(n_jobs=-1)]: Done 52248 tasks      | elapsed:   45.7s\n",
      "[Parallel(n_jobs=-1)]: Done 73048 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 90000 out of 90000 | elapsed:  1.3min finished\n"
     ]
    }
   ],
   "source": [
    "# dtc3 = DecisionTreeClassifier(class_weight='balanced',criterion='gini',ccp_alpha=0.006599999)\n",
    "# dtc3.fit(stimXtrain,stimYtrain)\n",
    "# dtc3ytrainpred = dtc3.predict(stimXtrain)\n",
    "# dtc3ytestpred = dtc3.predict(stimXtest)\n",
    "parameters={'min_impurity_decrease':[0+x/100 for x in range(1,10)],'ccp_alpha':[x/60 for x in list(range(0,100,1))],'class_weight':['balanced'],'criterion':['entropy','gini'],'min_samples_leaf':range(0,20,2)}\n",
    "dtc3 = GridSearchCV(DecisionTreeClassifier(),param_grid=parameters,verbose=True,n_jobs=-1)\n",
    "dtc3.fit(stimXtrain,stimYtrain)\n",
    "dtcytrainpred = dtc3.predict(stimXtrain)\n",
    "dtcytestpred = dtc3.predict(stimXtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5307382302081204, 0.5123364835068017)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(stimYtrain,dtcytrainpred,average='weighted'),f1_score(stimYtest,dtcytestpred,average='weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "polymodel4 = dtc.best_estimator_\n",
    "polymodel5 = dtc2.best_estimator_\n",
    "polymodel6 = dtc3.best_estimator_\n",
    "\n",
    "pkl.dump(polymodel4,open('PolyModel4.pkl','wb'))\n",
    "pkl.dump(polymodel5,open('PolyModel5.pkl','wb'))\n",
    "pkl.dump(polymodel6,open('PolyModel6.pkl','wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knearest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 49 candidates, totalling 245 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 222 out of 245 | elapsed:    2.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 245 out of 245 | elapsed:    2.2s finished\n"
     ]
    }
   ],
   "source": [
    "parameters={'n_neighbors':range(1,50)}\n",
    "knn = GridSearchCV(KNeighborsClassifier(),param_grid=parameters,verbose=True,n_jobs=-1)\n",
    "knn.fit(stimXtrain,stimYtrain)\n",
    "knnytrainpred = knn.predict(stimXtrain)\n",
    "knnytestpred = knn.predict(stimXtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1080 candidates, totalling 5400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 440 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1440 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2840 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=-1)]: Done 4640 tasks      | elapsed:   27.3s\n",
      "[Parallel(n_jobs=-1)]: Done 5400 out of 5400 | elapsed:   31.2s finished\n"
     ]
    }
   ],
   "source": [
    "parameters={'n_neighbors':range(50,1130)}\n",
    "knn2 = GridSearchCV(KNeighborsClassifier(),param_grid=parameters,verbose=True,n_jobs=-1)\n",
    "knn2.fit(stimXtrain,stimYtrain)\n",
    "knn2ytrainpred = knn2.predict(stimXtrain)\n",
    "knn2ytestpred = knn2.predict(stimXtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "polymodel7 = knn.best_estimator_\n",
    "polymodel8 = knn2.best_estimator_\n",
    "\n",
    "pkl.dump(polymodel7,open('PolyModel7.pkl','wb'))\n",
    "pkl.dump(polymodel8,open('PolyModel8.pkl','wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2030 candidates, totalling 10150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   38.6s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed: 13.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2426 tasks      | elapsed: 19.4min\n",
      "[Parallel(n_jobs=-1)]: Done 3176 tasks      | elapsed: 27.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4026 tasks      | elapsed: 35.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4976 tasks      | elapsed: 44.7min\n",
      "[Parallel(n_jobs=-1)]: Done 6026 tasks      | elapsed: 54.7min\n",
      "[Parallel(n_jobs=-1)]: Done 7176 tasks      | elapsed: 68.0min\n"
     ]
    }
   ],
   "source": [
    "parameters={'ccp_alpha':[x/10 for x in list(range(0,10,1))],'max_features':range(1,30,1),'class_weight':['balanced'],'criterion':['entropy'],'n_estimators':[100,200,300,400,500,1000,2000]}\n",
    "rfc = GridSearchCV(RandomForestClassifier(),param_grid=parameters,verbose=True,n_jobs=-1)\n",
    "rfc.fit(stimXtrain,stimYtrain)\n",
    "rfcytrainpred = rfc.predict(stimXtrain)\n",
    "rfcytestpred = rfc.predict(stimXtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfctrainypred = rfc.predict(stimXtrain)\n",
    "rfctestypred = rfc.predict(stimXtest)\n",
    "f1_score(rfctrainypred,stimYtrain,average='weighted'),f1_score(rfctestypred,stimYtest,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters={'ccp_alpha':[x/10 for x in list(range(0,10,1))]\n",
    "                         ,'random_state':[True],'max_features':[0,1,2,3,4,5,6,7,15,30,43]\n",
    "                         ,'class_weight':['balanced'],'criterion':['gini']\n",
    "                         ,'oob_score':[True,False],'n_estimators':[100,200,300,400,500,1000,2000]}\n",
    "rfc2 = GridSearchCV(RandomForestClassifier(),param_grid=parameters,verbose=True,n_jobs=-1)\n",
    "rfc2.fit(stimXtrain,stimYtrain)\n",
    "rfc2ytrainpred = rfc2.predict(stimXtrain)\n",
    "rfc2ytestpred = rfc2.predict(stimXtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc2trainypred = rfc2.predict(stimXtrain)\n",
    "rfc2testypred = rfc2.predict(stimXtest)\n",
    "f1_score(rfc2trainypred,stimYtrain,average='weighted'),f1_score(rfc2testypred,stimYtest,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polymodel9 = rfc.best_estimator_\n",
    "polymodel10 = rfc2.best_estimator_\n",
    "\n",
    "pkl.dump(polymodel9,open('PolyModel9.pkl','wb'))\n",
    "pkl.dump(polymodel10,open('PolyModel10.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('dtc2',\n",
       "                              DecisionTreeClassifier(ccp_alpha=0.006,\n",
       "                                                     class_weight='balanced')),\n",
       "                             ('rfc2',\n",
       "                              RandomForestClassifier(ccp_alpha=0.02,\n",
       "                                                     class_weight='balanced',\n",
       "                                                     criterion='entropy',\n",
       "                                                     max_features=30,\n",
       "                                                     n_estimators=100000,\n",
       "                                                     n_jobs=-1, oob_score=True,\n",
       "                                                     verbose=True)),\n",
       "                             ('knn', KNeighborsClassifier(n_neighbors=250)),\n",
       "                             ('knn2', KNeighborsClassifier(n_neigh...\n",
       "                              LogisticRegression(max_iter=4000,\n",
       "                                                 solver='liblinear', tol=1,\n",
       "                                                 warm_start=True)),\n",
       "                             ('dtc', DecisionTreeClassifier(ccp_alpha=0.0055)),\n",
       "                             ('dtc3',\n",
       "                              DecisionTreeClassifier(ccp_alpha=0.006599999,\n",
       "                                                     class_weight='balanced')),\n",
       "                             ('rfc',\n",
       "                              RandomForestClassifier(ccp_alpha=0.009,\n",
       "                                                     class_weight='balanced',\n",
       "                                                     max_depth=6,\n",
       "                                                     max_features=6,\n",
       "                                                     n_estimators=1000,\n",
       "                                                     oob_score=True))],\n",
       "                 n_jobs=-1, verbose=True, voting='soft')"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vtc = VotingClassifier([('dtc2',dtc2),('rfc2',rfc2),('knn',knn),('knn2',knn2),('log',mod),('log3',mod3),('log2',mod2),('dtc',dtc),('dtc3',dtc3),(\"rfc\",rfc)],voting='soft',verbose = True,n_jobs=-1)\n",
    "vtc.fit(stimXtrain,stimYtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 2426 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 3176 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 4026 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=12)]: Done 4976 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=12)]: Done 6026 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=12)]: Done 7176 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=12)]: Done 8426 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=12)]: Done 9776 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=12)]: Done 11226 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=12)]: Done 12776 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=12)]: Done 14426 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=12)]: Done 16176 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=12)]: Done 18026 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=12)]: Done 19976 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=12)]: Done 22026 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=12)]: Done 24176 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=12)]: Done 26426 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=12)]: Done 28776 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=12)]: Done 31226 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=12)]: Done 33776 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=12)]: Done 36426 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=12)]: Done 39176 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=12)]: Done 42026 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=12)]: Done 44976 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=12)]: Done 48026 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=12)]: Done 51176 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=12)]: Done 54426 tasks      | elapsed:   11.7s\n",
      "[Parallel(n_jobs=12)]: Done 57776 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=12)]: Done 61226 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=12)]: Done 64776 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=12)]: Done 68426 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=12)]: Done 72176 tasks      | elapsed:   14.8s\n",
      "[Parallel(n_jobs=12)]: Done 76026 tasks      | elapsed:   15.4s\n",
      "[Parallel(n_jobs=12)]: Done 79976 tasks      | elapsed:   16.1s\n",
      "[Parallel(n_jobs=12)]: Done 84026 tasks      | elapsed:   16.8s\n",
      "[Parallel(n_jobs=12)]: Done 88176 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=12)]: Done 92426 tasks      | elapsed:   19.3s\n",
      "[Parallel(n_jobs=12)]: Done 96776 tasks      | elapsed:   20.5s\n",
      "[Parallel(n_jobs=12)]: Done 100000 out of 100000 | elapsed:   21.2s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 176 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=12)]: Done 426 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=12)]: Done 776 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=12)]: Done 1226 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=12)]: Done 1776 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=12)]: Done 2426 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=12)]: Done 3176 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=12)]: Done 4026 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=12)]: Done 4976 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=12)]: Done 6026 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=12)]: Done 7176 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=12)]: Done 8426 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=12)]: Done 9776 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=12)]: Done 11226 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=12)]: Done 12776 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=12)]: Done 14426 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=12)]: Done 16176 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=12)]: Done 18026 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=12)]: Done 19976 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=12)]: Done 22026 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=12)]: Done 24176 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=12)]: Done 26426 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=12)]: Done 28776 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=12)]: Done 31226 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=12)]: Done 33776 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=12)]: Done 36426 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=12)]: Done 39176 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=12)]: Done 42026 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=12)]: Done 44976 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=12)]: Done 48026 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=12)]: Done 51176 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=12)]: Done 54426 tasks      | elapsed:   12.2s\n",
      "[Parallel(n_jobs=12)]: Done 57776 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=12)]: Done 61226 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=12)]: Done 64776 tasks      | elapsed:   14.6s\n",
      "[Parallel(n_jobs=12)]: Done 68426 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=12)]: Done 72176 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=12)]: Done 76026 tasks      | elapsed:   17.5s\n",
      "[Parallel(n_jobs=12)]: Done 79976 tasks      | elapsed:   18.3s\n",
      "[Parallel(n_jobs=12)]: Done 84026 tasks      | elapsed:   19.1s\n",
      "[Parallel(n_jobs=12)]: Done 88176 tasks      | elapsed:   19.9s\n",
      "[Parallel(n_jobs=12)]: Done 92426 tasks      | elapsed:   20.7s\n",
      "[Parallel(n_jobs=12)]: Done 96776 tasks      | elapsed:   21.5s\n",
      "[Parallel(n_jobs=12)]: Done 100000 out of 100000 | elapsed:   22.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6582121313304148 0.5951090892458898\n"
     ]
    }
   ],
   "source": [
    "vtcypred = vtc.predict(stimXtest)\n",
    "vtcytrain = vtc.predict(stimXtrain)\n",
    "\n",
    "print(f1_score(vtcytrain,stimYtrain,average='weighted'),f1_score(stimYtest,vtcypred,average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump(vtc,open('vtcpoly.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
